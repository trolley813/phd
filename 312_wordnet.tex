
WordNet \cite{Miller95wordnet:a} --- лексическая база данных английского языка, разработанная в Принстонском университете. 
Она представляет собой электронный словарь-тезаурус и набор семантических сетей для английского языка. 

Словарь, представленный в WordNet, состоит из 4 семантических сетей для основных знаменательных частей речи: 
существительных, глаголов, прилагательных и наречий.

Этапы применения WordNet к модели, описанной в предыдущем разделе:
\begin{enumerate}[1)]
    \item провести грамматический разбор запроса, выявить части речи, соответствующие словам;
    \item определить (хотя бы приближенно) возможную семантику слова в соответствии с контекстом;
    \item найти с использованием WordNet похожие слова (согласно метрике семантической близости);
    \item ранжировать поисковую выдачу в соответствии с семантической близостью слов и $n$-грамм для
    последующего обучения нейронной сети (с помощью классических алгоритмов либо субъективно);
    \item обучить нейросеть и провести сравнение результатов.
\end{enumerate}

Семантическая близость $n$-грамм может быть определена как среднее геометрическое коэффициентов близости отдельных слов:
\begin{equation}
    \label{eq:ngram-sim}
    \begin{aligned}
    S(u_1u_2\dots u_n, w_1w_2\dots w_n) = \left( \prod\limits_{i=1}^n {S(u_i, w_i)} \right)^{\frac1n}= \\
    = \sqrt[n]{S(u_1, w_1)S(u_1, w_2)\dots S(u_n, w_n)},
    \end{aligned}
\end{equation}
где $u_1u_2\dots u_n$ и $w_1w_2\dots w_n$ --- сравниваемые $n$-граммы (здесь мы считаем, что порядок слов имеет значение).

Формула \eqref{eq:ngram-sim} может быть продиктована следующими соображениями:
\begin{enumerate}[1)]
    \item коэффициент близости должен равняться некоторому <<среднему>> из коэффициентов близости отдельных слов;
    \item с другой стороны, наличие неподобных пар слов должно приводить к значительному (но не полному) снижению 
    близости всей $n$-граммы (что позволяет отсечь, например, среднее арифметическое).
\end{enumerate}

Одним из базовых методов для выведения семантики слова в контексте (разрешения неоднозначности, англ. disambiguation)
является метод Леска \cite{10.1145/318723.318728}, разработанный инженером компании Bell Labs М. Леском в 1986 году.
Идея метода заключается в поиске значения слова в списке словарных определений с учетом контекста, где это слово использовано. 
Основным критерием для выбора значения послужило следующее правило: заложенный в этом определении смысл должен был частично
совпадать со смыслом значений соседних слов в контексте.

Алгоритм Леска работает в следующей последовательности:
\begin{enumerate}[1)]
    \item На первом шаге алгоритма отделяется контекст для рассматриваемого слова --- чаще всего, не более 10 расположенных 
        рядом слов.
    \item Далее, для рассматриваемого слова (или его начальной формы) ищутся все определения в некоторой базе знаний 
        (например, толковом словаре, хотя данный вариант редко используется непосредственно).
    \item Затем происходит поиск слов из контекста в каждом найденном определении. Если какое-либо слово из контекста
        присутствует в определении, то данное определение получает "<балл"> --- т. е. увеличивается счетчик совпадений.
    \item Наконец, происходит ранжирование определений по значениям счетчика совпадений. Чем выше значение счетчика, тем более
        подходящим к контексту считается определение.
\end{enumerate}

Рассмотрим следующий пример: согласно Большому толковому словарю русского языка С. А. Кузнецова \cite{kuznecov2008noveishiy},
слово "<штанга"> в русском языке имеет следующие значения:
\begin{enumerate}[1)]
    \item металлический стержень, используемый как деталь во многих механизмах;
    \item боковая стойка (иногда и верхняя перекладина) футбольных, хоккейных и т.п. ворот;
    \item снаряд для занятий тяжёлой атлетикой, состоящий из металлического стержня, на концах которого укреплены
        съёмные диски различного веса.
\end{enumerate}

Теперь рассмотрим следующие предложения, содержащие слово "<штанга">:
\begin{enumerate}[1)]
    \item Троллейбусная штанга, как правило, изготовляется из металлической трубы переменного сечения.
    \item В футбольном матче между "<Спартаком"> и "<Зенитом"> форвард ленинградцев дважды поразил штангу, а защитник москвичей
    отметился голом в свои ворота.
    \item На чемпионате мира по тяжелой атлетике наш спортсмен поднял штагу рекордного веса.
\end{enumerate}

Как видим, в первом предложении присутствует слово "<металлический">, которое есть только в первом определении слова "<штанга">.
Во втором предложении такую же роль играют слова "<футбольный"> и "<ворота">, в третьем --- "<вес"> и "<тяжелая атлетика">.
Таким образом, в данном примере алгоритм работает безупречно, правильно определяя значение слова в зависимости от контекста.

Чаще, к сожалению, возникает обратная ситуация --- а именно, когда словарное определение оказывается недостаточно емким и не включает
в себя наиболее часто встречающиеся в контексте слова. Поэтому чаще применяются модификации алгоритма, основанные не только на
словарных определениях, но и на примерах употребления слов в данных значениях в контексте.

Для применения алгоритма воспользуемся методом, содержащимся непосредственно в библиотеке NLTK. Он возвращает для заданного слова
в предложении наиболее подходящий (с точки зрения алгоритма) набор синонимов, иначе --- синонимический ряд (англ. synset), 
представляющий из себя слова со схожим значением, объединенные в узел семантической сети. В WordNet каждый такой набор дополнен
определением и примерами употребления слов в контексте. Слова, имеющие несколько значений, включаются в несколько синонимических рядов
(выбор между которыми в контексте заданного поискового запроса или предложения будет осуществляться с помощью алгоритма Леска)
и могут быть причислены к различным синтаксическим и лексическим классам.

Синонимические ряды, в отличие от лишенных контекста слов, уже подлежат количественной оценке схожести.